# OCTANOL TO WATER (ΔG_octanol - ΔG_water) TRANSFER FREE ENERGY PREDICTIONS
#
Predictions:
SM25,SM25_micro000,-4.29,0.27,0.49
SM26,SM26_micro000,-1.22,0.00,0.49
SM27,SM27_micro000,-2.14,0.06,0.49
SM28,SM28_micro000,-1.23,0.34,0.49
SM29,SM29_micro000,-2.37,0.07,0.49
SM30,SM30_micro000,-4.23,0.16,0.49
SM31,SM31_micro000,-2.95,0.24,0.49
SM32,SM32_micro000,-3.23,0.05,0.49
SM33,SM33_micro000,-5.19,0.18,0.49
SM34,SM34_micro000,-3.87,0.21,0.49
SM35,SM35_micro000,-1.81,0.32,0.49
SM36,SM36_micro000,-3.72,0.24,0.49
SM37,SM37_micro000,-2.36,0.34,0.49
SM38,SM38_micro000,-1.36,0.16,0.49
SM39,SM39_micro000,-3.20,0.08,0.49
SM40,SM40_micro000,-1.57,0.35,0.49
SM41,SM41_micro000,-2.75,0.00,0.49
SM42,SM42_micro000,-5.03,0.00,0.49
SM43,SM43_micro000,-3.39,0.20,0.49
SM44,SM44_micro000,-1.24,0.00,0.49
SM45,SM45_micro000,-3.27,0.06,0.49
SM46,SM46_micro000,-1.71,0.07,0.49

#
#
# Please list your name, using only UTF-8 characters as described above. The "Participant name:" entry is required.
Participant name:
Chris Loschen

#
#
# Please list your organization/affiliation, using only UTF-8 characters as described above.
Participant organization:
not-organized/private

#
#
# NAME SECTION
#
# The 'Name:' keyword is required as shown here.
Name:
ffsampled_deeplearning_cl2

#
#
# COMPUTE TIME SECTION
#
# Please provide the average compute time across all of the molecules.
# For physical methods, report the GPU and/or CPU compute time in hours.
# For empirical methods, report the query time in hours.
# Create a new line for each processor type.
# The 'Compute time:' keyword is required as shown here.
Compute time:
0.01 hours, GPU

#
# COMPUTING AND HARDWARE SECTION
#
# Please provide details of the computing resources that were used to train models and make predictions.
# Please specify compute time for training models and querying separately for empirical prediction methods.
# Provide a detailed description of the hardware used to run the simulations.
# The 'Computing and hardware:' keyword is required as shown here.
Computing and hardware:
All the simulations were performed on one GeForce GTX 1080 on a single linux machine.
Training of 100 epochs took about 1 hours.

# SOFTWARE SECTION
#
# List all major software packages used and their versions.
# Create a new line for each software.
# The 'Software:' keyword is required.
Software:
Schnetpack 0.3
Fastai 1.0.6
RDKit 2020.03.3

# METHOD CATEGORY SECTION
#
# State which method category your prediction method is better described as:
# `Physical (MM)`, `Physical (QM)`, `Empirical`, or `Mixed`.
# Pick only one category label.
# The `Category:` keyword is required.
Category:
Empirical

# METHOD DESCRIPTION SECTION
#
# Methodology and computational details.
# Level of details should be roughly equivalent to that used in a publication.
# Please include the values of key parameters with units.
# Please explain how statistical uncertainties were estimated.
#
# If you have evaluated additional microstates, please report their SMILES strings and populations of all the microstates in this section.
# If you used a microstate other than the challenge provided microstate (`SMXX_micro000`), please list your chosen `Molecule ID` (in the form of `SMXX_extra001`) along with the SMILES string in your methods description.
#
# Use as many lines of text as you need.
# All text following the 'Method:' keyword will be regarded as part of your free text methods description.
Method:
A modified version of the deeplearning package schnetpack was used which is based on the work of Schütt et al.[1] and may be seen as a variant of message passing neural networks. However, the input is only 3D structure based and does not rely on any kind of precomputed descriptors, rather the molecular representations are learned on-the-fly during training.  The neural net was trained with the fastai library, version 1 [2] using accelerated learning, so-called super-convergence as published by L. Smith et al.[3] and other tools available from the fastai library, which allow for fast iterations during testing.
A curated logP dataset was assembled mainly from the work of Mansouri et al.[4] and used for training, testing and validation. Input structures for the neural net have been generated from the provided SMILES via the distance geometry approach as implemented in the RDKIT and a quick conformational sampling was carried out using the MMFF94 forcefield. 
Before the 3D structure generation molecules have been brought into a canonical representation with the RDKit. Statistical uncertainties were estimated based on the average of 10 distinct predictions runs and on the overall test sets performance.

[1] Schutt, K. T., Kessel, P., Gastegger, M., Nicoli, K. A., Tkatchenko, A., & Müller, K. R. (2018). SchNetPack: A deep learning toolbox for atomistic systems. Journal of chemical theory and computation, 15(1), 448-455.
[2] https://fastai1.fast.ai/ 
[3] Smith, L. N., & Topin, N. (2019, May). Super-convergence: Very fast training of neural networks using large learning rates. In Artificial Intelligence and Machine Learning for Multi-Domain Operations Applications (Vol. 11006, p. 1100612). International Society for Optics and Photonics.
[4] Mansouri, K., Grulke, C. M., Judson, R. S., & Williams, A. J. (2018). OPERA models for predicting physicochemical properties and environmental fate endpoints. Journal of cheminformatics, 10(1), 10.) 

#
# All submissions must either be ranked or non-ranked.
# Only one ranked submission per participant is allowed.
# Multiple ranked submissions from the same participant will not be judged.
# Non-ranked submissions are accepted so we can verify that they were made before the deadline.
# The "Ranked:" keyword is required, and expects a Boolean value (True/False)
Ranked:
False
